
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>plotcc</title><meta name="generator" content="MATLAB 7.12"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2011-11-02"><meta name="DC.source" content="plotcc.m"><style type="text/css">

body {
  background-color: white;
  margin:10px;
}

h1 {
  color: #990000; 
  font-size: x-large;
}

h2 {
  color: #990000;
  font-size: medium;
}

/* Make the text shrink to fit narrow windows, but not stretch too far in 
wide windows. */ 
p,h1,h2,div.content div {
  max-width: 600px;
  /* Hack for IE6 */
  width: auto !important; width: 600px;
}

pre.codeinput {
  background: #EEEEEE;
  padding: 10px;
}
@media print {
  pre.codeinput {word-wrap:break-word; width:100%;}
} 

span.keyword {color: #0000FF}
span.comment {color: #228B22}
span.string {color: #A020F0}
span.untermstring {color: #B20000}
span.syscmd {color: #B28C00}

pre.codeoutput {
  color: #666666;
  padding: 10px;
}

pre.error {
  color: red;
}

p.footer {
  text-align: right;
  font-size: xx-small;
  font-weight: lighter;
  font-style: italic;
  color: gray;
}

  </style></head><body><div class="content"><h2>Contents</h2><div><ul><li><a href="#1">plotcc.m</a></li><li><a href="#2">Load the data</a></li><li><a href="#3">Fit class-conditional Gaussians for each class</a></li><li><a href="#4">Plot the contours</a></li><li><a href="#5">Repeat without Naive assumption</a></li><li><a href="#6">Plot the contours</a></li></ul></div><h2>plotcc.m<a name="1"></a></h2><p>From A First Course in Machine Learning, Chapter 5. Simon Rogers, 01/11/11 [simon.rogers@glasgow.ac.uk] Computing and plotting class-conditional densities for a Bayes classifier</p><pre class="codeinput">clear <span class="string">all</span>;close <span class="string">all</span>;
</pre><h2>Load the data<a name="2"></a></h2><pre class="codeinput">load <span class="string">../data/bc_data</span>

<span class="comment">% Plot the data</span>
cl = unique(t);
col = {<span class="string">'ko'</span>,<span class="string">'kd'</span>,<span class="string">'ks'</span>}
fcol = {[1 0 0],[0 1 0],[0 0 1]};
figure(1);
hold <span class="string">off</span>
<span class="keyword">for</span> c = 1:length(cl)
    pos = find(t==cl(c));
    plot(X(pos,1),X(pos,2),col{c},<span class="keyword">...</span>
        <span class="string">'markersize'</span>,10,<span class="string">'linewidth'</span>,2,<span class="keyword">...</span>
        <span class="string">'markerfacecolor'</span>,fcol{c});
    hold <span class="string">on</span>
<span class="keyword">end</span>
xlim([-3 7])
ylim([-6 6])
</pre><pre class="codeoutput">
col = 

    'ko'    'kd'    'ks'

</pre><img vspace="5" hspace="5" src="plotcc_01.png" alt=""> <h2>Fit class-conditional Gaussians for each class<a name="3"></a></h2><p>Using the Naive (independence) assumption</p><pre class="codeinput"><span class="keyword">for</span> c = 1:length(cl)
    pos = find(t==cl(c));
    <span class="comment">% Find the means</span>
    class_mean(c,:) = mean(X(pos,:));
    class_var(c,:) = var(X(pos,:),1);
<span class="keyword">end</span>
</pre><h2>Plot the contours<a name="4"></a></h2><pre class="codeinput">[Xv,Yv] = meshgrid(-3:0.1:7,-6:0.1:6);
<span class="keyword">for</span> c = 1:length(cl)
    temp = [Xv(:)-class_mean(c,1) Yv(:)-class_mean(c,2)];
    tempc = diag(class_var(c,:));
    const = -log(2*pi) - log(det(tempc));
    Probs = exp(const - 0.5*diag(temp*inv(tempc)*temp'));
    contour(Xv,Yv,reshape(Probs,size(Xv)));
<span class="keyword">end</span>
</pre><img vspace="5" hspace="5" src="plotcc_02.png" alt=""> <h2>Repeat without Naive assumption<a name="5"></a></h2><pre class="codeinput">class_var = [];
<span class="keyword">for</span> c = 1:length(cl)
    pos = find(t==cl(c));
    <span class="comment">% Find the means</span>
    class_mean(c,:) = mean(X(pos,:));
    class_var(:,:,c) = cov(X(pos,:),1);
<span class="keyword">end</span>
</pre><h2>Plot the contours<a name="6"></a></h2><pre class="codeinput">figure(1);
hold <span class="string">off</span>
<span class="keyword">for</span> c = 1:length(cl)
    pos = find(t==cl(c));
    plot(X(pos,1),X(pos,2),col{c},<span class="keyword">...</span>
        <span class="string">'markersize'</span>,10,<span class="string">'linewidth'</span>,2,<span class="keyword">...</span>
        <span class="string">'markerfacecolor'</span>,fcol{c});
    hold <span class="string">on</span>
<span class="keyword">end</span>
xlim([-3 7])
ylim([-6 6])
[Xv,Yv] = meshgrid(-3:0.1:7,-6:0.1:6);
<span class="keyword">for</span> c = 1:length(cl)
    temp = [Xv(:)-class_mean(c,1) Yv(:)-class_mean(c,2)];
    tempc = class_var(:,:,c);
    const = -log(2*pi) - log(det(tempc));
    Probs = exp(const - 0.5*diag(temp*inv(tempc)*temp'));
    contour(Xv,Yv,reshape(Probs,size(Xv)));
<span class="keyword">end</span>
</pre><img vspace="5" hspace="5" src="plotcc_03.png" alt=""> <p class="footer"><br>
      Published with MATLAB&reg; 7.12<br></p></div><!--
##### SOURCE BEGIN #####
%% plotcc.m
% From A First Course in Machine Learning, Chapter 5.
% Simon Rogers, 01/11/11 [simon.rogers@glasgow.ac.uk]
% Computing and plotting class-conditional densities for a Bayes classifier
clear all;close all;


%% Load the data
load ../data/bc_data

% Plot the data
cl = unique(t);
col = {'ko','kd','ks'}
fcol = {[1 0 0],[0 1 0],[0 0 1]};
figure(1);
hold off
for c = 1:length(cl)
    pos = find(t==cl(c));
    plot(X(pos,1),X(pos,2),col{c},...
        'markersize',10,'linewidth',2,...
        'markerfacecolor',fcol{c});
    hold on
end
xlim([-3 7])
ylim([-6 6])

%% Fit class-conditional Gaussians for each class
% Using the Naive (independence) assumption
for c = 1:length(cl)
    pos = find(t==cl(c));
    % Find the means
    class_mean(c,:) = mean(X(pos,:));
    class_var(c,:) = var(X(pos,:),1);
end

%% Plot the contours
[Xv,Yv] = meshgrid(-3:0.1:7,-6:0.1:6);
for c = 1:length(cl)
    temp = [Xv(:)-class_mean(c,1) Yv(:)-class_mean(c,2)];
    tempc = diag(class_var(c,:));
    const = -log(2*pi) - log(det(tempc));
    Probs = exp(const - 0.5*diag(temp*inv(tempc)*temp'));
    contour(Xv,Yv,reshape(Probs,size(Xv)));
end



%% Repeat without Naive assumption
class_var = [];
for c = 1:length(cl)
    pos = find(t==cl(c));
    % Find the means
    class_mean(c,:) = mean(X(pos,:));
    class_var(:,:,c) = cov(X(pos,:),1);
end

%% Plot the contours
figure(1);
hold off
for c = 1:length(cl)
    pos = find(t==cl(c));
    plot(X(pos,1),X(pos,2),col{c},...
        'markersize',10,'linewidth',2,...
        'markerfacecolor',fcol{c});
    hold on
end
xlim([-3 7])
ylim([-6 6])
[Xv,Yv] = meshgrid(-3:0.1:7,-6:0.1:6);
for c = 1:length(cl)
    temp = [Xv(:)-class_mean(c,1) Yv(:)-class_mean(c,2)];
    tempc = class_var(:,:,c);
    const = -log(2*pi) - log(det(tempc));
    Probs = exp(const - 0.5*diag(temp*inv(tempc)*temp'));
    contour(Xv,Yv,reshape(Probs,size(Xv)));
end
##### SOURCE END #####
--></body></html>