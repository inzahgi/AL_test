
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>svmsoft</title><meta name="generator" content="MATLAB 7.13"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2011-11-09"><meta name="DC.source" content="svmsoft.m"><style type="text/css">

body {
  background-color: white;
  margin:10px;
}

h1 {
  color: #990000; 
  font-size: x-large;
}

h2 {
  color: #990000;
  font-size: medium;
}

/* Make the text shrink to fit narrow windows, but not stretch too far in 
wide windows. */ 
p,h1,h2,div.content div {
  max-width: 600px;
  /* Hack for IE6 */
  width: auto !important; width: 600px;
}

pre.codeinput {
  background: #EEEEEE;
  padding: 10px;
}
@media print {
  pre.codeinput {word-wrap:break-word; width:100%;}
} 

span.keyword {color: #0000FF}
span.comment {color: #228B22}
span.string {color: #A020F0}
span.untermstring {color: #B20000}
span.syscmd {color: #B28C00}

pre.codeoutput {
  color: #666666;
  padding: 10px;
}

pre.error {
  color: red;
}

p.footer {
  text-align: right;
  font-size: xx-small;
  font-weight: lighter;
  font-style: italic;
  color: gray;
}

  </style></head><body><div class="content"><h2>Contents</h2><div><ul><li><a href="#1">svmsoft.m</a></li><li><a href="#2">Generate the data</a></li><li><a href="#3">Plot the data</a></li><li><a href="#4">Setup the optimisation problem</a></li><li><a href="#5">Loop over various values of the margin parameter</a></li><li><a href="#7">Plot the data, decision boundary and Support vectors</a></li></ul></div><h2>svmsoft.m<a name="1"></a></h2><p>From A First Course in Machine Learning, Chapter 4. Simon Rogers, 01/11/11 [simon.rogers@glasgow.ac.uk] Soft margin SVM</p><pre class="codeinput">clear <span class="string">all</span>;close <span class="string">all</span>;
</pre><h2>Generate the data<a name="2"></a></h2><pre class="codeinput">x = [randn(20,2);randn(20,2)+4];
t = [repmat(-1,20,1);repmat(1,20,1)];
<span class="comment">% Add a bad point</span>
x = [x;2 1];
t = [t;1];
</pre><h2>Plot the data<a name="3"></a></h2><pre class="codeinput">ma = {<span class="string">'ko'</span>,<span class="string">'ks'</span>};
fc = {[0 0 0],[1 1 1]};
tv = unique(t);
figure(1); hold <span class="string">off</span>
<span class="keyword">for</span> i = 1:length(tv)
    pos = find(t==tv(i));
    plot(x(pos,1),x(pos,2),ma{i},<span class="string">'markerfacecolor'</span>,fc{i});
    hold <span class="string">on</span>
<span class="keyword">end</span>
</pre><img vspace="5" hspace="5" src="svmsoft_01.png" alt=""> <h2>Setup the optimisation problem<a name="4"></a></h2><pre class="codeinput">N = size(x,1);
K = x*x';
H = (t*t').*K + 1e-5*eye(N);
f = repmat(1,N,1);
A = [];b = [];
LB = repmat(0,N,1); UB = repmat(inf,N,1);
Aeq = t';beq = 0;


warning <span class="string">off</span>
</pre><h2>Loop over various values of the margin parameter<a name="5"></a></h2><pre class="codeinput">Cvals = [10 5 2 1 0.5 0.1 0.05 0.01];
<span class="keyword">for</span> cv = 1:length(Cvals);
</pre><pre class="codeinput">    UB = repmat(Cvals(cv),N,1);
    <span class="comment">% Following line runs the SVM</span>
    alpha = quadprog(H,-f,A,b,Aeq,beq,LB,UB);
    <span class="comment">% Compute the bias</span>
    fout = sum(repmat(alpha.*t,1,N).*K,1)';
    pos = find(alpha&gt;1e-6);
    bias = mean(t(pos)-fout(pos));
</pre><pre class="codeoutput">Optimization terminated.
</pre><pre class="codeoutput">Optimization terminated.
</pre><pre class="codeoutput">Optimization terminated.
</pre><pre class="codeoutput">Optimization terminated.
</pre><pre class="codeoutput">Optimization terminated.
</pre><pre class="codeoutput">Optimization terminated.
</pre><pre class="codeoutput">Optimization terminated.
</pre><pre class="codeoutput">Optimization terminated.
</pre><h2>Plot the data, decision boundary and Support vectors<a name="7"></a></h2><pre class="codeinput">    figure(1);hold <span class="string">off</span>
    pos = find(alpha&gt;1e-6);
    plot(x(pos,1),x(pos,2),<span class="string">'ko'</span>,<span class="string">'markersize'</span>,15,<span class="string">'markerfacecolor'</span>,[0.6 0.6 0.6],<span class="keyword">...</span>
        <span class="string">'markeredgecolor'</span>,[0.6 0.6 0.6]);
    hold <span class="string">on</span>
    <span class="keyword">for</span> i = 1:length(tv)
        pos = find(t==tv(i));
        plot(x(pos,1),x(pos,2),ma{i},<span class="string">'markerfacecolor'</span>,fc{i});
    <span class="keyword">end</span>

    xp = xlim;
    yl = ylim;
    <span class="comment">% Because this is a linear SVM, we can compute w and plot the decision</span>
    <span class="comment">% boundary exactly.</span>
    w = sum(repmat(alpha.*t,1,2).*x,1)';
    yp = -(bias + w(1)*xp)/w(2);
    plot(xp,yp,<span class="string">'k'</span>,<span class="string">'linewidth'</span>,2);
    ylim(yl);
    ti = sprintf(<span class="string">'C: %g'</span>,Cvals(cv));
    title(ti);
</pre><img vspace="5" hspace="5" src="svmsoft_02.png" alt=""> <img vspace="5" hspace="5" src="svmsoft_03.png" alt=""> <img vspace="5" hspace="5" src="svmsoft_04.png" alt=""> <img vspace="5" hspace="5" src="svmsoft_05.png" alt=""> <img vspace="5" hspace="5" src="svmsoft_06.png" alt=""> <img vspace="5" hspace="5" src="svmsoft_07.png" alt=""> <img vspace="5" hspace="5" src="svmsoft_08.png" alt=""> <img vspace="5" hspace="5" src="svmsoft_09.png" alt=""> <pre class="codeinput"><span class="keyword">end</span>
</pre><p class="footer"><br>
      Published with MATLAB&reg; 7.13<br></p></div><!--
##### SOURCE BEGIN #####
%% svmsoft.m
% From A First Course in Machine Learning, Chapter 4.
% Simon Rogers, 01/11/11 [simon.rogers@glasgow.ac.uk]
% Soft margin SVM
clear all;close all;


%% Generate the data
x = [randn(20,2);randn(20,2)+4];
t = [repmat(-1,20,1);repmat(1,20,1)];
% Add a bad point
x = [x;2 1];
t = [t;1];
%% Plot the data
ma = {'ko','ks'};
fc = {[0 0 0],[1 1 1]};
tv = unique(t);
figure(1); hold off
for i = 1:length(tv)
    pos = find(t==tv(i));
    plot(x(pos,1),x(pos,2),ma{i},'markerfacecolor',fc{i});
    hold on
end

%% Setup the optimisation problem
N = size(x,1);
K = x*x';
H = (t*t').*K + 1e-5*eye(N);
f = repmat(1,N,1);
A = [];b = [];
LB = repmat(0,N,1); UB = repmat(inf,N,1);
Aeq = t';beq = 0;


warning off
%% Loop over various values of the margin parameter
Cvals = [10 5 2 1 0.5 0.1 0.05 0.01];
for cv = 1:length(Cvals);
    %%
    UB = repmat(Cvals(cv),N,1);
    % Following line runs the SVM
    alpha = quadprog(H,-f,A,b,Aeq,beq,LB,UB);
    % Compute the bias
    fout = sum(repmat(alpha.*t,1,N).*K,1)';
    pos = find(alpha>1e-6);
    bias = mean(t(pos)-fout(pos));
    %% Plot the data, decision boundary and Support vectors
    figure(1);hold off
    pos = find(alpha>1e-6);
    plot(x(pos,1),x(pos,2),'ko','markersize',15,'markerfacecolor',[0.6 0.6 0.6],...
        'markeredgecolor',[0.6 0.6 0.6]);
    hold on
    for i = 1:length(tv)
        pos = find(t==tv(i));
        plot(x(pos,1),x(pos,2),ma{i},'markerfacecolor',fc{i});
    end

    xp = xlim;
    yl = ylim;
    % Because this is a linear SVM, we can compute w and plot the decision
    % boundary exactly.
    w = sum(repmat(alpha.*t,1,2).*x,1)';
    yp = -(bias + w(1)*xp)/w(2);
    plot(xp,yp,'k','linewidth',2);
    ylim(yl);
    ti = sprintf('C: %g',Cvals(cv));
    title(ti);
end
##### SOURCE END #####
--></body></html>