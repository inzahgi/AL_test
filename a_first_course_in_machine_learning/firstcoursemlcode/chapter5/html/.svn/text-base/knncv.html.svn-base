
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>knncv</title><meta name="generator" content="MATLAB 7.13"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2011-11-09"><meta name="DC.source" content="knncv.m"><style type="text/css">

body {
  background-color: white;
  margin:10px;
}

h1 {
  color: #990000; 
  font-size: x-large;
}

h2 {
  color: #990000;
  font-size: medium;
}

/* Make the text shrink to fit narrow windows, but not stretch too far in 
wide windows. */ 
p,h1,h2,div.content div {
  max-width: 600px;
  /* Hack for IE6 */
  width: auto !important; width: 600px;
}

pre.codeinput {
  background: #EEEEEE;
  padding: 10px;
}
@media print {
  pre.codeinput {word-wrap:break-word; width:100%;}
} 

span.keyword {color: #0000FF}
span.comment {color: #228B22}
span.string {color: #A020F0}
span.untermstring {color: #B20000}
span.syscmd {color: #B28C00}

pre.codeoutput {
  color: #666666;
  padding: 10px;
}

pre.error {
  color: red;
}

p.footer {
  text-align: right;
  font-size: xx-small;
  font-weight: lighter;
  font-style: italic;
  color: gray;
}

  </style></head><body><div class="content"><h2>Contents</h2><div><ul><li><a href="#1">knncv.m</a></li><li><a href="#2">Generate some data</a></li><li><a href="#3">Plot the data</a></li><li><a href="#4">loop over values of K</a></li><li><a href="#5">Permute the data and split into folds</a></li><li><a href="#7">Plot the results</a></li></ul></div><h2>knncv.m<a name="1"></a></h2><p>From A First Course in Machine Learning, Chapter 4. Simon Rogers, 01/11/11 [simon.rogers@glasgow.ac.uk] Cross-validation over K in KNN</p><pre class="codeinput">clear <span class="string">all</span>;close <span class="string">all</span>;
</pre><h2>Generate some data<a name="2"></a></h2><pre class="codeinput">N1 = 100; N2 = 20; <span class="comment">% Class sizes</span>
x = [randn(N1,2);randn(N2,2)+2];
t = [repmat(0,N1,1);repmat(1,N2,1)];
N = size(x,1);
</pre><h2>Plot the data<a name="3"></a></h2><pre class="codeinput">ma = {<span class="string">'ko'</span>,<span class="string">'ks'</span>};
fc = {[0 0 0],[1 1 1]};
tv = unique(t);
figure(1); hold <span class="string">off</span>
<span class="keyword">for</span> i = 1:length(tv)
    pos = find(t==tv(i));
    plot(x(pos,1),x(pos,2),ma{i},<span class="string">'markerfacecolor'</span>,fc{i});
    hold <span class="string">on</span>
<span class="keyword">end</span>
</pre><img vspace="5" hspace="5" src="knncv_01.png" alt=""> <h2>loop over values of K<a name="4"></a></h2><pre class="codeinput">Nfold = 10;
Kvals = [1:2:30];
Nrep = 100;
Errors = zeros(length(Kvals),Nfold,Nrep);
<span class="keyword">for</span> rep = 1:Nrep
</pre><h2>Permute the data and split into folds<a name="5"></a></h2><pre class="codeinput">    order = randperm(N);
    Nfold = 10; <span class="comment">% 10-fold CV</span>
    sizes = repmat(floor(N/Nfold),1,Nfold);
    sizes(end) = sizes(end) + N - sum(sizes);
    csizes = [0 cumsum(sizes)];
    <span class="keyword">for</span> kv = 1:length(Kvals)
        K = Kvals(kv);
        <span class="comment">% Loop over folds</span>
        <span class="keyword">for</span> fold = 1:Nfold
            trainX = x;
            traint = t;
            foldindex = order(csizes(fold)+1:csizes(fold+1));
            trainX(foldindex,:) = [];
            traint(foldindex) = [];
            testX = x(foldindex,:);
            testt = t(foldindex);

            <span class="comment">% Do the KNN</span>
            classes = zeros(size(testX,1),1);
            <span class="keyword">for</span> i = 1:size(testX,1)
                this = testX(i,:);
                dists = sum((trainX - repmat(this,size(trainX,1),1)).^2,2);
                [d I] = sort(dists,<span class="string">'ascend'</span>);
                [a,b] = hist(traint(I(1:K)),unique(t));
                pos = find(a==max(a));
                <span class="keyword">if</span> length(pos)&gt;1
                    temp_order = randperm(length(pos));
                    pos = pos(temp_order(1));
                <span class="keyword">end</span>
                classes(i) = b(pos);
            <span class="keyword">end</span>
            Errors(kv,fold,rep) = sum(classes~=testt);
        <span class="keyword">end</span>
    <span class="keyword">end</span>
</pre><pre class="codeinput"><span class="keyword">end</span>
</pre><h2>Plot the results<a name="7"></a></h2><pre class="codeinput">figure(1); hold <span class="string">off</span>
s = sum(sum(Errors,3),2)./(N*Nrep);
plot(Kvals,s);
xlabel(<span class="string">'K'</span>);
ylabel(<span class="string">'Error'</span>);
</pre><img vspace="5" hspace="5" src="knncv_02.png" alt=""> <p class="footer"><br>
      Published with MATLAB&reg; 7.13<br></p></div><!--
##### SOURCE BEGIN #####
%% knncv.m
% From A First Course in Machine Learning, Chapter 4.
% Simon Rogers, 01/11/11 [simon.rogers@glasgow.ac.uk]
% Cross-validation over K in KNN
clear all;close all;

%% Generate some data
N1 = 100; N2 = 20; % Class sizes
x = [randn(N1,2);randn(N2,2)+2];
t = [repmat(0,N1,1);repmat(1,N2,1)];
N = size(x,1);

%% Plot the data
ma = {'ko','ks'};
fc = {[0 0 0],[1 1 1]};
tv = unique(t);
figure(1); hold off
for i = 1:length(tv)
    pos = find(t==tv(i));
    plot(x(pos,1),x(pos,2),ma{i},'markerfacecolor',fc{i});
    hold on
end

%% loop over values of K
Nfold = 10;
Kvals = [1:2:30];
Nrep = 100;
Errors = zeros(length(Kvals),Nfold,Nrep);
for rep = 1:Nrep
    %% Permute the data and split into folds
    order = randperm(N);
    Nfold = 10; % 10-fold CV
    sizes = repmat(floor(N/Nfold),1,Nfold);
    sizes(end) = sizes(end) + N - sum(sizes);
    csizes = [0 cumsum(sizes)];
    for kv = 1:length(Kvals)
        K = Kvals(kv);
        % Loop over folds
        for fold = 1:Nfold
            trainX = x;
            traint = t;
            foldindex = order(csizes(fold)+1:csizes(fold+1));
            trainX(foldindex,:) = [];
            traint(foldindex) = [];
            testX = x(foldindex,:);
            testt = t(foldindex);

            % Do the KNN
            classes = zeros(size(testX,1),1);
            for i = 1:size(testX,1)
                this = testX(i,:);
                dists = sum((trainX - repmat(this,size(trainX,1),1)).^2,2);
                [d I] = sort(dists,'ascend');
                [a,b] = hist(traint(I(1:K)),unique(t));
                pos = find(a==max(a));
                if length(pos)>1
                    temp_order = randperm(length(pos));
                    pos = pos(temp_order(1));
                end
                classes(i) = b(pos);
            end
            Errors(kv,fold,rep) = sum(classes~=testt);
        end
    end
  
end

%% Plot the results
figure(1); hold off
s = sum(sum(Errors,3),2)./(N*Nrep);
plot(Kvals,s);
xlabel('K');
ylabel('Error');
##### SOURCE END #####
--></body></html>