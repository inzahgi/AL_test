
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>newspred</title><meta name="generator" content="MATLAB 7.13"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2011-11-09"><meta name="DC.source" content="newspred.m"><style type="text/css">

body {
  background-color: white;
  margin:10px;
}

h1 {
  color: #990000; 
  font-size: x-large;
}

h2 {
  color: #990000;
  font-size: medium;
}

/* Make the text shrink to fit narrow windows, but not stretch too far in 
wide windows. */ 
p,h1,h2,div.content div {
  max-width: 600px;
  /* Hack for IE6 */
  width: auto !important; width: 600px;
}

pre.codeinput {
  background: #EEEEEE;
  padding: 10px;
}
@media print {
  pre.codeinput {word-wrap:break-word; width:100%;}
} 

span.keyword {color: #0000FF}
span.comment {color: #228B22}
span.string {color: #A020F0}
span.untermstring {color: #B20000}
span.syscmd {color: #B28C00}

pre.codeoutput {
  color: #666666;
  padding: 10px;
}

pre.error {
  color: red;
}

p.footer {
  text-align: right;
  font-size: xx-small;
  font-weight: lighter;
  font-style: italic;
  color: gray;
}

  </style></head><body><div class="content"><h2>Contents</h2><div><ul><li><a href="#1">newspred.m</a></li><li><a href="#2">Load the data</a></li><li><a href="#3">Compute the class conditional q parameters</a></li><li><a href="#4">Compute the test probabilities</a></li><li><a href="#5">Normalise</a></li><li><a href="#6">Visualise the probabilities</a></li><li><a href="#7">Make the confusion matrix</a></li></ul></div><h2>newspred.m<a name="1"></a></h2><p>From A First Course in Machine Learning, Chapter 5. Simon Rogers, 01/11/11 [simon.rogers@glasgow.ac.uk] Naive Bayesian classifier on the 20 newsgroup data</p><pre class="codeinput">clear <span class="string">all</span>; close <span class="string">all</span>;
</pre><h2>Load the data<a name="2"></a></h2><pre class="codeinput">load <span class="string">../data/newsgroups</span>
</pre><h2>Compute the class conditional q parameters<a name="3"></a></h2><pre class="codeinput">alpha = 2; <span class="comment">% Smoothing parameter</span>
M = size(X,2); <span class="comment">% Vocabulary size</span>
q = zeros(20,M);

<span class="keyword">for</span> c = 1:20
    pos = find(t==c);
    q(c,:) = (alpha - 1 + sum(X(pos,:),1))./(M*(alpha-1) + sum(sum(X(pos,:))));
<span class="keyword">end</span>
</pre><h2>Compute the test probabilities<a name="4"></a></h2><p>Do this with logs for numerical stability. Note: this takes quite a long time!</p><pre class="codeinput">Nt = size(Xt,1);
testP = zeros(Nt,20);
<span class="keyword">for</span> c = 1:20
    fprintf(<span class="string">'\nClass %g'</span>,c);
    testP(:,c) = sum(Xt.*log(repmat(q(c,:),Nt,1)),2);
<span class="keyword">end</span>
</pre><pre class="codeoutput">
Class 1
Class 2
Class 3
Class 4
Class 5
Class 6
Class 7
Class 8
Class 9
Class 10
Class 11
Class 12
Class 13
Class 14
Class 15
Class 16
Class 17
Class 18
Class 19
Class 20</pre><h2>Normalise<a name="5"></a></h2><pre class="codeinput">C = 20;
prior = repmat(1/C,1,C); <span class="comment">% Prior class probabilities</span>
testP = testP + repmat(log(prior),Nt,1);
testP = exp(testP - repmat(max(testP,[],2),1,20));
testP = testP./repmat(sum(testP,2),1,20);
</pre><h2>Visualise the probabilities<a name="6"></a></h2><pre class="codeinput">imagesc(testP);
</pre><img vspace="5" hspace="5" src="newspred_01.png" alt=""> <h2>Make the confusion matrix<a name="7"></a></h2><p>Assign to max probability</p><pre class="codeinput">assignments = (testP == repmat(max(testP,[],2),1,C));
[r,c] = find(assignments);
[r I] = sort(r);
c = c(I);
confusion = zeros(C);
<span class="keyword">for</span> predicted = 1:C
    <span class="keyword">for</span> true = 1:C
        confusion(predicted,true) = sum(testt==true &amp; c==predicted);
    <span class="keyword">end</span>
<span class="keyword">end</span>

imagesc(confusion)
xlabel(<span class="string">'True class'</span>);
ylabel(<span class="string">'Predicted class'</span>);
</pre><img vspace="5" hspace="5" src="newspred_02.png" alt=""> <p class="footer"><br>
      Published with MATLAB&reg; 7.13<br></p></div><!--
##### SOURCE BEGIN #####
%% newspred.m
% From A First Course in Machine Learning, Chapter 5.
% Simon Rogers, 01/11/11 [simon.rogers@glasgow.ac.uk]
% Naive Bayesian classifier on the 20 newsgroup data
clear all; close all;

%% Load the data
load ../data/newsgroups

%% Compute the class conditional q parameters
alpha = 2; % Smoothing parameter
M = size(X,2); % Vocabulary size
q = zeros(20,M);

for c = 1:20
    pos = find(t==c);
    q(c,:) = (alpha - 1 + sum(X(pos,:),1))./(M*(alpha-1) + sum(sum(X(pos,:))));
end


%% Compute the test probabilities
% Do this with logs for numerical stability.
% Note: this takes quite a long time!
Nt = size(Xt,1);
testP = zeros(Nt,20);
for c = 1:20
    fprintf('\nClass %g',c);
    testP(:,c) = sum(Xt.*log(repmat(q(c,:),Nt,1)),2);
end

%% Normalise
C = 20;
prior = repmat(1/C,1,C); % Prior class probabilities
testP = testP + repmat(log(prior),Nt,1);
testP = exp(testP - repmat(max(testP,[],2),1,20));
testP = testP./repmat(sum(testP,2),1,20);

%% Visualise the probabilities
imagesc(testP);

%% Make the confusion matrix
% Assign to max probability
assignments = (testP == repmat(max(testP,[],2),1,C));
[r,c] = find(assignments);
[r I] = sort(r);
c = c(I);
confusion = zeros(C);
for predicted = 1:C
    for true = 1:C
        confusion(predicted,true) = sum(testt==true & c==predicted);
    end
end

imagesc(confusion)
xlabel('True class');
ylabel('Predicted class');
##### SOURCE END #####
--></body></html>