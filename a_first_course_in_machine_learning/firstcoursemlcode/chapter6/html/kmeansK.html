
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>kmeansK</title><meta name="generator" content="MATLAB 7.13"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2011-11-10"><meta name="DC.source" content="kmeansK.m"><style type="text/css">

body {
  background-color: white;
  margin:10px;
}

h1 {
  color: #990000; 
  font-size: x-large;
}

h2 {
  color: #990000;
  font-size: medium;
}

/* Make the text shrink to fit narrow windows, but not stretch too far in 
wide windows. */ 
p,h1,h2,div.content div {
  max-width: 600px;
  /* Hack for IE6 */
  width: auto !important; width: 600px;
}

pre.codeinput {
  background: #EEEEEE;
  padding: 10px;
}
@media print {
  pre.codeinput {word-wrap:break-word; width:100%;}
} 

span.keyword {color: #0000FF}
span.comment {color: #228B22}
span.string {color: #A020F0}
span.untermstring {color: #B20000}
span.syscmd {color: #B28C00}

pre.codeoutput {
  color: #666666;
  padding: 10px;
}

pre.error {
  color: red;
}

p.footer {
  text-align: right;
  font-size: xx-small;
  font-weight: lighter;
  font-style: italic;
  color: gray;
}

  </style></head><body><div class="content"><h2>Contents</h2><div><ul><li><a href="#1">kmeansK.m</a></li><li><a href="#2">Load the data</a></li><li><a href="#3">Plot the data</a></li><li><a href="#4">Make the boxplot</a></li></ul></div><h2>kmeansK.m<a name="1"></a></h2><p>From A First Course in Machine Learning, Chapter 6. Simon Rogers, 01/11/11 [simon.rogers@glasgow.ac.uk] Overfitting in K-means</p><pre class="codeinput">clear <span class="string">all</span>;close <span class="string">all</span>;
</pre><h2>Load the data<a name="2"></a></h2><pre class="codeinput">load <span class="string">../data/kmeansdata</span>
</pre><h2>Plot the data<a name="3"></a></h2><pre class="codeinput">figure(1);hold <span class="string">off</span>
plot(X(:,1),X(:,2),<span class="string">'ko'</span>);

Kvals = 1:10;
Nreps = 50;
total_distance = zeros(length(Kvals),Nreps);
<span class="keyword">for</span> kv = 1:length(Kvals)
    <span class="keyword">for</span> rep = 1:Nreps
        K = Kvals(kv);
        cluster_means = rand(K,2)*10-5;
        converged = 0;
        N = size(X,1);
        cluster_assignments = zeros(N,K);
        di = zeros(N,K);
        <span class="keyword">while</span> ~converged

            <span class="comment">% Update assignments</span>
            <span class="keyword">for</span> k = 1:K
                di(:,k) = sum((X - repmat(cluster_means(k,:),N,1)).^2,2);
            <span class="keyword">end</span>
            old_assignments = cluster_assignments;
            cluster_assignments = (di == repmat(min(di,[],2),1,K));
            <span class="keyword">if</span> sum(sum(old_assignments~=cluster_assignments))==0
                converged = 1;
            <span class="keyword">end</span>

            <span class="comment">% Update means</span>
            <span class="keyword">for</span> k = 1:K
                <span class="keyword">if</span> sum(cluster_assignments(:,k))==0
                    <span class="comment">% This cluster is empty, randomise it</span>
                    cluster_means(k,:) = rand(1,2)*10-5;
                <span class="keyword">else</span>
                    cluster_means(k,:) = mean(X(cluster_assignments(:,k),:),1);
                <span class="keyword">end</span>
            <span class="keyword">end</span>
        <span class="keyword">end</span>
        <span class="comment">% Compute the distance</span>
        total_distance(kv,rep) = sum(sum(di.*cluster_assignments));

    <span class="keyword">end</span>
<span class="keyword">end</span>
</pre><img vspace="5" hspace="5" src="kmeansK_01.png" alt=""> <h2>Make the boxplot<a name="4"></a></h2><pre class="codeinput">figure(1);hold <span class="string">off</span>
boxplot(log(total_distance)');
xlabel(<span class="string">'K'</span>);
ylabel(<span class="string">'Log D'</span>);
</pre><img vspace="5" hspace="5" src="kmeansK_02.png" alt=""> <p class="footer"><br>
      Published with MATLAB&reg; 7.13<br></p></div><!--
##### SOURCE BEGIN #####
%% kmeansK.m
% From A First Course in Machine Learning, Chapter 6.
% Simon Rogers, 01/11/11 [simon.rogers@glasgow.ac.uk]
% Overfitting in K-means
clear all;close all;

%% Load the data
load ../data/kmeansdata

%% Plot the data
figure(1);hold off
plot(X(:,1),X(:,2),'ko');

Kvals = 1:10;
Nreps = 50;
total_distance = zeros(length(Kvals),Nreps);
for kv = 1:length(Kvals)
    for rep = 1:Nreps
        K = Kvals(kv);
        cluster_means = rand(K,2)*10-5;
        converged = 0;
        N = size(X,1);
        cluster_assignments = zeros(N,K);
        di = zeros(N,K);
        while ~converged
   
            % Update assignments
            for k = 1:K
                di(:,k) = sum((X - repmat(cluster_means(k,:),N,1)).^2,2);
            end
            old_assignments = cluster_assignments;
            cluster_assignments = (di == repmat(min(di,[],2),1,K));
            if sum(sum(old_assignments~=cluster_assignments))==0
                converged = 1;
            end

            % Update means
            for k = 1:K   
                if sum(cluster_assignments(:,k))==0
                    % This cluster is empty, randomise it
                    cluster_means(k,:) = rand(1,2)*10-5;
                else
                    cluster_means(k,:) = mean(X(cluster_assignments(:,k),:),1);
                end
            end
        end
        % Compute the distance
        total_distance(kv,rep) = sum(sum(di.*cluster_assignments));
        
    end
end

%% Make the boxplot
figure(1);hold off
boxplot(log(total_distance)');
xlabel('K');
ylabel('Log D');

##### SOURCE END #####
--></body></html>