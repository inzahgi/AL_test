
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>binmix</title><meta name="generator" content="MATLAB 7.13"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2011-11-14"><meta name="DC.source" content="binmix.m"><style type="text/css">

body {
  background-color: white;
  margin:10px;
}

h1 {
  color: #990000; 
  font-size: x-large;
}

h2 {
  color: #990000;
  font-size: medium;
}

/* Make the text shrink to fit narrow windows, but not stretch too far in 
wide windows. */ 
p,h1,h2,div.content div {
  max-width: 600px;
  /* Hack for IE6 */
  width: auto !important; width: 600px;
}

pre.codeinput {
  background: #EEEEEE;
  padding: 10px;
}
@media print {
  pre.codeinput {word-wrap:break-word; width:100%;}
} 

span.keyword {color: #0000FF}
span.comment {color: #228B22}
span.string {color: #A020F0}
span.untermstring {color: #B20000}
span.syscmd {color: #B28C00}

pre.codeoutput {
  color: #666666;
  padding: 10px;
}

pre.error {
  color: red;
}

p.footer {
  text-align: right;
  font-size: xx-small;
  font-weight: lighter;
  font-style: italic;
  color: gray;
}

  </style></head><body><div class="content"><h2>Contents</h2><div><ul><li><a href="#1">binmix.m</a></li><li><a href="#2">Generate the data</a></li><li><a href="#3">Image the data</a></li><li><a href="#4">Run the mixture</a></li><li><a href="#5">Plot the bound</a></li><li><a href="#6">Visualise the clusters</a></li><li><a href="#9">Image the q values</a></li></ul></div><h2>binmix.m<a name="1"></a></h2><p>From A First Course in Machine Learning, Chapter 6. Simon Rogers, 01/11/11 [simon.rogers@glasgow.ac.uk] Mixture model for binary data</p><pre class="codeinput">clear <span class="string">all</span>;close <span class="string">all</span>;
</pre><h2>Generate the data<a name="2"></a></h2><pre class="codeinput">K = 5;
priors = repmat(1/K,1,K);
D = 10; <span class="comment">%Number of dimensions</span>
probs = rand(K,D); <span class="comment">% The binary probabilities</span>
N = 100; <span class="comment">% The number of data objects</span>

t = [];
<span class="keyword">for</span> n = 1:N
    <span class="comment">% Which component?</span>
    pos = find(rand&lt;cumsum(priors));
    t(n,1) = pos(1);
    <span class="keyword">for</span> d = 1:D
        X(n,d) = (rand&lt;probs(t(n,1),d));
    <span class="keyword">end</span>
<span class="keyword">end</span>

<span class="comment">% Sort the data for visualisation</span>
[t I] = sort(t);
X = X(I,:);
</pre><h2>Image the data<a name="3"></a></h2><pre class="codeinput">figure(1);hold <span class="string">off</span>
imagesc(X);
</pre><img vspace="5" hspace="5" src="binmix_01.png" alt=""> <h2>Run the mixture<a name="4"></a></h2><pre class="codeinput">K = 5; <span class="comment">% Try changing this</span>
B = [];
B(1) = -inf;
pkd = rand(K,D);
pri = repmat(1/K,1,K);
converged = 0;
it = 0;
tol = 1e-2;
MaxIts = 100;
alpha = 2;beta = 2; <span class="comment">% MAP Smoothing parameters - set to 1 to turn off smoothing (may cause numerical instability)</span>
<span class="keyword">while</span> 1
    it = it + 1;

    <span class="comment">% Update q</span>
    temp = zeros(N,K);
    <span class="keyword">for</span> k = 1:K
        temp(:,k) = sum(X.*log(repmat(pkd(k,:),N,1)) + <span class="keyword">...</span>
            (1-X).*log(repmat(1-pkd(k,:),N,1)),2);
    <span class="keyword">end</span>
    temp = temp + repmat(log(pri),N,1);

    <span class="comment">% Compute B</span>
    <span class="keyword">if</span> it&gt;1
        B(it) = sum(sum(q.*log(repmat(priors,N,1)))) + <span class="keyword">...</span>
        sum(sum(q.*temp)) - <span class="keyword">...</span>
        sum(sum(q.*log(q)));
        <span class="comment">% Prior contributions (due to smoothing)</span>
        B(it) = B(it) + K*D*gammaln(alpha+beta) - <span class="keyword">...</span>
            K*D*gammaln(alpha) - K*D*gammaln(beta);
        B(it) + B(it) + (alpha-1)*sum(sum(log(pkd))) + <span class="keyword">...</span>
            (beta - 1)*sum(sum(log(1-pkd)));
        <span class="keyword">if</span> abs(B(it)-B(it-1))&lt;tol
            converged = 1;
        <span class="keyword">end</span>
    <span class="keyword">end</span>

    <span class="keyword">if</span> converged == 1 || it&gt;MaxIts
        <span class="keyword">break</span>
    <span class="keyword">end</span>

    q = exp(temp - repmat(max(temp,[],2),1,K));
    q = q./repmat(sum(q,2),1,K);



    <span class="comment">% Update priors</span>
    pri = mean(q,1);

    <span class="comment">% Update probabilites</span>
    <span class="keyword">for</span> k = 1:K
        pkd(k,:) = (alpha - 1 + sum(repmat(q(:,k),1,D).*X,1))./(alpha + beta - 2 + sum(q(:,k)));
    <span class="keyword">end</span>

<span class="keyword">end</span>
</pre><h2>Plot the bound<a name="5"></a></h2><pre class="codeinput">figure(1); hold <span class="string">off</span>
plot(B)
xlabel(<span class="string">'Iterations'</span>);
ylabel(<span class="string">'Bound'</span>);
</pre><img vspace="5" hspace="5" src="binmix_02.png" alt=""> <h2>Visualise the clusters<a name="6"></a></h2><pre class="codeinput">assi = (q==repmat(max(q,[],2),1,K));
<span class="keyword">for</span> k = 1:K
</pre><pre class="codeinput">    figure(k);hold <span class="string">off</span>
    imagesc(X(assi(:,k),:));
    ti = sprintf(<span class="string">'Cluster: %g'</span>,k);
    title(ti);
</pre><img vspace="5" hspace="5" src="binmix_03.png" alt=""> <img vspace="5" hspace="5" src="binmix_04.png" alt=""> <img vspace="5" hspace="5" src="binmix_05.png" alt=""> <img vspace="5" hspace="5" src="binmix_06.png" alt=""> <img vspace="5" hspace="5" src="binmix_07.png" alt=""> <pre class="codeinput"><span class="keyword">end</span>
</pre><h2>Image the q values<a name="9"></a></h2><p>Note that because the data are in order, we should see clear block structure.  It won't be perfect: our clusters were randomly generated so there is no gaurantee that they are particularly different.</p><pre class="codeinput">figure(1);hold <span class="string">off</span>
imagesc(q);
xlabel(<span class="string">'Cluster'</span>);
ylabel(<span class="string">'Object'</span>);
figure(2);hold <span class="string">off</span>
imagesc(assi);
xlabel(<span class="string">'Cluster'</span>);
ylabel(<span class="string">'Object'</span>);
</pre><img vspace="5" hspace="5" src="binmix_08.png" alt=""> <img vspace="5" hspace="5" src="binmix_09.png" alt=""> <p class="footer"><br>
      Published with MATLAB&reg; 7.13<br></p></div><!--
##### SOURCE BEGIN #####
%% binmix.m
% From A First Course in Machine Learning, Chapter 6.
% Simon Rogers, 01/11/11 [simon.rogers@glasgow.ac.uk]
% Mixture model for binary data
clear all;close all;

%% Generate the data
K = 5;
priors = repmat(1/K,1,K);
D = 10; %Number of dimensions
probs = rand(K,D); % The binary probabilities
N = 100; % The number of data objects

t = [];
for n = 1:N
    % Which component?
    pos = find(rand<cumsum(priors));
    t(n,1) = pos(1);
    for d = 1:D
        X(n,d) = (rand<probs(t(n,1),d));
    end
end

% Sort the data for visualisation
[t I] = sort(t);
X = X(I,:);

%% Image the data
figure(1);hold off
imagesc(X);

%% Run the mixture
K = 5; % Try changing this
B = [];
B(1) = -inf;
pkd = rand(K,D);
pri = repmat(1/K,1,K);
converged = 0;
it = 0;
tol = 1e-2;
MaxIts = 100;
alpha = 2;beta = 2; % MAP Smoothing parameters - set to 1 to turn off smoothing (may cause numerical instability)
while 1
    it = it + 1;
    
    % Update q
    temp = zeros(N,K);
    for k = 1:K
        temp(:,k) = sum(X.*log(repmat(pkd(k,:),N,1)) + ...
            (1-X).*log(repmat(1-pkd(k,:),N,1)),2);
    end
    temp = temp + repmat(log(pri),N,1);
    
    % Compute B
    if it>1
        B(it) = sum(sum(q.*log(repmat(priors,N,1)))) + ...
        sum(sum(q.*temp)) - ...
        sum(sum(q.*log(q)));
        % Prior contributions (due to smoothing)
        B(it) = B(it) + K*D*gammaln(alpha+beta) - ...
            K*D*gammaln(alpha) - K*D*gammaln(beta);
        B(it) + B(it) + (alpha-1)*sum(sum(log(pkd))) + ...
            (beta - 1)*sum(sum(log(1-pkd)));
        if abs(B(it)-B(it-1))<tol
            converged = 1;
        end
    end

    if converged == 1 || it>MaxIts
        break
    end

    q = exp(temp - repmat(max(temp,[],2),1,K));
    q = q./repmat(sum(q,2),1,K);
    
    
    
    % Update priors
    pri = mean(q,1);
    
    % Update probabilites
    for k = 1:K
        pkd(k,:) = (alpha - 1 + sum(repmat(q(:,k),1,D).*X,1))./(alpha + beta - 2 + sum(q(:,k)));
    end
    
end


%% Plot the bound
figure(1); hold off
plot(B)
xlabel('Iterations');
ylabel('Bound');

%% Visualise the clusters
assi = (q==repmat(max(q,[],2),1,K));
for k = 1:K
    %%
    figure(k);hold off
    imagesc(X(assi(:,k),:));
    ti = sprintf('Cluster: %g',k);
    title(ti);
end

%% Image the q values
% Note that because the data are in order, we should see clear block
% structure.  It won't be perfect: our clusters were randomly generated so
% there is no gaurantee that they are particularly different.
figure(1);hold off
imagesc(q);
xlabel('Cluster');
ylabel('Object');
figure(2);hold off
imagesc(assi);
xlabel('Cluster');
ylabel('Object');
##### SOURCE END #####
--></body></html>